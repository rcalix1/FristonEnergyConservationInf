# Friston Energy Conservation Inference

* Prof. Karl J. Friston


## Key Papers

* https://www.fil.ion.ucl.ac.uk/~karl/

## Uncertainty Minimization

*  active inference
*  brain mapping + neuroimaging analysis methods
*  SPM + DCM
*  Gaussian Random Field theory
*   but then he totally switched his research to study "active inference" - a theory of how brains work - which is somewhat related to Reinforcement Learning (RL) in #AI  ðŸ’¡He gave a talk at OHBM that was the most complex I have ever seen given at any conference, explaining the Free Energy Principle (FEP). which describes how systems (biological or artificial) minimize uncertainty about their environment by inferring the causes of sensory inputs + acting to fulfil their prior beliefs or reduce uncertainty. As far as I can tell, the main point is that agents (such as humans) try to minimize "variational free energy", actively measuring the difference between their brain's model of the world + its sensory experiences.  ðŸ’¡The AI people who do reinforcement learning [3] (e.g., programming self-driving cars) are doing a related thing, where an agent learns a "policy" to maximize a cumulative reward signal, given a state + actions; the agent balances trying new actions (exploration) with seeking known rewards, so the AI people in the room are using somewhat similar frameworks that focus on adaptive behavior to achieve the "best" outcomes. ðŸ’¡Even so, these frameworks (active inference and reinforcement learning) aren't completely similar: RL maximises an external reward signal, but active Inference minimises a combination of "surprise "(discrepancy between observations + expectations) + uncertainty (lack of confidence in beliefs) but also (2) creates a generative model of the environment that predicts sensory inputs, given internal states. ðŸ’¡ Presumably the AI people in the room are not incorporating intrinsic motivation into their algorithms but they may do now. [1] I didn't go, but if you want to watch it, you can watch the whole thing for 200 USD and it's well worth it. The NeuroAI workshop was great, as was Arnaud Doucet's flow matching talk, which will give you a new perspective on Generative AI [2] en.wikipedia.org/wiki/Karl_J._Fâ€¦ [3] actually not all AI people are doing RL, and most AI books with predictive and generative AI have RL as the last chapter or the last 1/3, which can you can ignore if you are not designing autonomous agents (it is still interesting if you have time to read it).


## Energy conservation 



![screenshot2](IMG_9788.jpg)

![screenshot2](IMG_9787.jpg)

